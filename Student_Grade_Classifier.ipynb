{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c620cdfa",
   "metadata": {},
   "source": [
    "# Student Grade Classifier: Fundamentals of AI Project\n",
    "\n",
    "Welcome! This notebook will guide you step by step through building a Student Grade Classifier using the complete AI pipeline. Each section includes explanations and code, making it beginner-friendly. We will use Python, pandas, and scikit-learn.\n",
    "\n",
    "**Pipeline Steps:**\n",
    "1. Data Collection/Loading\n",
    "2. Preprocessing\n",
    "3. Model Development\n",
    "4. Evaluation\n",
    "5. Hyperparameter Tuning\n",
    "6. Deployment\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9546c809",
   "metadata": {},
   "source": [
    "## 1. Data Collection/Loading\n",
    "\n",
    "In this section, we'll load the student dataset and explore its contents. We'll use the pandas library to read the CSV file and inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846467f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:40:17.614713Z",
     "iopub.status.busy": "2025-05-25T11:40:17.611901Z",
     "iopub.status.idle": "2025-05-25T11:40:20.714581Z",
     "shell.execute_reply": "2025-05-25T11:40:20.712760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with the correct delimiter\n",
    "file_path = 'student-mat.csv'\n",
    "data = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Display the first 5 rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b006f",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "In this step, we will prepare the data for modeling. This includes:\n",
    "- Checking for and handling missing values\n",
    "- Encoding categorical variables (converting text columns to numbers)\n",
    "- Scaling numerical features (if needed)\n",
    "- Splitting the data into training and testing sets\n",
    "\n",
    "These steps ensure the data is clean and suitable for building a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3859f50c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:40:20.725871Z",
     "iopub.status.busy": "2025-05-25T11:40:20.724904Z",
     "iopub.status.idle": "2025-05-25T11:40:20.754104Z",
     "shell.execute_reply": "2025-05-25T11:40:20.751740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "school        0\n",
      "sex           0\n",
      "age           0\n",
      "address       0\n",
      "famsize       0\n",
      "Pstatus       0\n",
      "Medu          0\n",
      "Fedu          0\n",
      "Mjob          0\n",
      "Fjob          0\n",
      "reason        0\n",
      "guardian      0\n",
      "traveltime    0\n",
      "studytime     0\n",
      "failures      0\n",
      "schoolsup     0\n",
      "famsup        0\n",
      "paid          0\n",
      "activities    0\n",
      "nursery       0\n",
      "higher        0\n",
      "internet      0\n",
      "romantic      0\n",
      "famrel        0\n",
      "freetime      0\n",
      "goout         0\n",
      "Dalc          0\n",
      "Walc          0\n",
      "health        0\n",
      "absences      0\n",
      "G1            0\n",
      "G2            0\n",
      "G3            0\n",
      "dtype: int64\n",
      "\n",
      "After handling missing values, shape of data: (395, 33)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_values = data.isnull().sum()\n",
    "print('Missing values in each column:')\n",
    "print(missing_values)\n",
    "\n",
    "# If there are missing values, handle them (e.g., fill with mean/mode or drop rows)\n",
    "# For this dataset, we expect no missing values, but if any are found, handle accordingly\n",
    "data = data.dropna()\n",
    "print('\\nAfter handling missing values, shape of data:', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422d42d4",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables\n",
    "\n",
    "Many columns in the dataset are categorical (text). Machine learning models require numerical input, so we need to convert these columns to numbers. We'll use one-hot encoding to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08677d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:40:20.764512Z",
     "iopub.status.busy": "2025-05-25T11:40:20.763374Z",
     "iopub.status.idle": "2025-05-25T11:40:20.865309Z",
     "shell.execute_reply": "2025-05-25T11:40:20.861968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after encoding categorical variables: (395, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>...</th>\n",
       "      <th>guardian_mother</th>\n",
       "      <th>guardian_other</th>\n",
       "      <th>schoolsup_yes</th>\n",
       "      <th>famsup_yes</th>\n",
       "      <th>paid_yes</th>\n",
       "      <th>activities_yes</th>\n",
       "      <th>nursery_yes</th>\n",
       "      <th>higher_yes</th>\n",
       "      <th>internet_yes</th>\n",
       "      <th>romantic_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     4     4           2          2         0       4         3      4   \n",
       "1   17     1     1           1          2         0       5         3      3   \n",
       "2   15     1     1           1          2         3       4         3      2   \n",
       "3   15     4     2           1          3         0       3         2      2   \n",
       "4   16     3     3           1          2         0       4         3      2   \n",
       "\n",
       "   Dalc  ...  guardian_mother  guardian_other  schoolsup_yes  famsup_yes  \\\n",
       "0     1  ...             True           False           True       False   \n",
       "1     1  ...            False           False          False        True   \n",
       "2     2  ...             True           False           True       False   \n",
       "3     1  ...             True           False          False        True   \n",
       "4     1  ...            False           False          False        True   \n",
       "\n",
       "   paid_yes  activities_yes  nursery_yes  higher_yes  internet_yes  \\\n",
       "0     False           False         True        True         False   \n",
       "1     False           False        False        True          True   \n",
       "2      True           False         True        True          True   \n",
       "3      True            True         True        True          True   \n",
       "4      True           False         True        True         False   \n",
       "\n",
       "   romantic_yes  \n",
       "0         False  \n",
       "1         False  \n",
       "2         False  \n",
       "3          True  \n",
       "4         False  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical variables using one-hot encoding\n",
    "data_encoded = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "print('Shape after encoding categorical variables:', data_encoded.shape)\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c6045",
   "metadata": {},
   "source": [
    "### Splitting Data and Scaling Features\n",
    "\n",
    "Now, we will:\n",
    "- Split the data into features (X) and target (y).\n",
    "- Split the dataset into training and testing sets.\n",
    "- Scale the numerical features to ensure all features contribute equally to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413d045e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:40:20.878306Z",
     "iopub.status.busy": "2025-05-25T11:40:20.876011Z",
     "iopub.status.idle": "2025-05-25T11:40:25.383513Z",
     "shell.execute_reply": "2025-05-25T11:40:25.380011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (316, 41)\n",
      "Test set shape: (79, 41)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the target variable (for classification, let's predict if the final grade G3 >= 10: pass/fail)\n",
    "data_encoded['pass'] = (data_encoded['G3'] >= 10).astype(int)\n",
    "X = data_encoded.drop(['G3', 'pass'], axis=1)\n",
    "y = data_encoded['pass']\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Training set shape:', X_train_scaled.shape)\n",
    "print('Test set shape:', X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a2a4a7",
   "metadata": {},
   "source": [
    "## 3. Model Development\n",
    "\n",
    "In this step, we will build and train a machine learning model to classify whether a student passes or fails based on their features. We will use Logistic Regression, a simple and effective algorithm for binary classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099ff244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:40:25.400163Z",
     "iopub.status.busy": "2025-05-25T11:40:25.398115Z",
     "iopub.status.idle": "2025-05-25T11:40:25.793486Z",
     "shell.execute_reply": "2025-05-25T11:40:25.789072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Model training complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65318d5b",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "In this step, we will evaluate the performance of our trained model using the test data. We will use metrics such as accuracy, precision, recall, F1-score, and the confusion matrix to assess how well the model predicts student outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f542c70f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:40:25.809079Z",
     "iopub.status.busy": "2025-05-25T11:40:25.806952Z",
     "iopub.status.idle": "2025-05-25T11:40:25.934665Z",
     "shell.execute_reply": "2025-05-25T11:40:25.930274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "Precision: 0.94\n",
      "Recall: 0.83\n",
      "F1-score: 0.88\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23  3]\n",
      " [ 9 44]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79        26\n",
      "           1       0.94      0.83      0.88        53\n",
      "\n",
      "    accuracy                           0.85        79\n",
      "   macro avg       0.83      0.86      0.84        79\n",
      "weighted avg       0.86      0.85      0.85        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-score: {f1:.2f}')\n",
    "print('\\nConfusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "# Detailed classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3542ecf5",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning\n",
    "\n",
    "In this step, we will optimize our model by searching for the best hyperparameters using Grid Search. This helps improve model performance by systematically testing different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0509d208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:40:25.949911Z",
     "iopub.status.busy": "2025-05-25T11:40:25.948009Z",
     "iopub.status.idle": "2025-05-25T11:40:33.711636Z",
     "shell.execute_reply": "2025-05-25T11:40:33.708772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Classification Report (Tuned Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83        26\n",
      "           1       0.96      0.85      0.90        53\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.85      0.89      0.86        79\n",
      "weighted avg       0.89      0.87      0.88        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Best parameters:', grid_search.best_params_)\n",
    "\n",
    "# Retrain the model with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the tuned model on the test set\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report (Tuned Model):')\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35159f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:40:33.723834Z",
     "iopub.status.busy": "2025-05-25T11:40:33.721975Z",
     "iopub.status.idle": "2025-05-25T11:40:33.764249Z",
     "shell.execute_reply": "2025-05-25T11:40:33.760743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and scaler saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Save the trained model and scaler for CLI deployment\n",
    "joblib.dump(best_model, 'student_grade_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print('Model and scaler saved successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca6828df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:40:33.779584Z",
     "iopub.status.busy": "2025-05-25T11:40:33.777841Z",
     "iopub.status.idle": "2025-05-25T11:40:33.810497Z",
     "shell.execute_reply": "2025-05-25T11:40:33.806809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the feature names used for model input\n",
    "import joblib\n",
    "joblib.dump(X.columns.tolist(), 'feature_names.pkl')\n",
    "print('Feature names saved successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f780481",
   "metadata": {},
   "source": [
    "## Feature Selection: Reducing the Number of Features\n",
    "\n",
    "To simplify the model and make predictions easier, we will select the most important features using the coefficients from our trained Logistic Regression model. We'll retrain the model using only these top features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "838e415e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:40:33.827987Z",
     "iopub.status.busy": "2025-05-25T11:40:33.826558Z",
     "iopub.status.idle": "2025-05-25T11:40:34.065600Z",
     "shell.execute_reply": "2025-05-25T11:40:34.062604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most important features:\n",
      "G2             9.192319\n",
      "G1             2.701841\n",
      "school_MS      1.872498\n",
      "age            1.741739\n",
      "Fjob_other     1.365867\n",
      "Walc           1.283136\n",
      "Mjob_other     1.139375\n",
      "famsize_LE3    0.895714\n",
      "famrel         0.882027\n",
      "sex_M          0.872307\n",
      "dtype: float64\n",
      "\n",
      "Selected features for new model: ['G2', 'G1', 'school_MS', 'age', 'Fjob_other', 'Walc', 'Mjob_other', 'famsize_LE3', 'famrel', 'sex_M', 'guardian_mother', 'freetime', 'failures', 'studytime', 'Dalc']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83        26\n",
      "           1       0.96      0.85      0.90        53\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.85      0.89      0.86        79\n",
      "weighted avg       0.89      0.87      0.88        79\n",
      "\n",
      "Reduced-feature model, scaler, and feature names saved for deployment (15 features).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get feature importance from the trained Logistic Regression model\n",
    "feature_importance = pd.Series(np.abs(best_model.coef_[0]), index=X.columns)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "\n",
    "# Display the top 10 most important features\n",
    "print('Top 10 most important features:')\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Select the top N features (now 15 for more information)\n",
    "N = 15\n",
    "top_features = feature_importance.head(N).index.tolist()\n",
    "print(f'\\nSelected features for new model: {top_features}')\n",
    "\n",
    "# Prepare new feature set\n",
    "X_reduced = X[top_features]\n",
    "\n",
    "# Split the data again\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reduced, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler_r = StandardScaler()\n",
    "X_train_r_scaled = scaler_r.fit_transform(X_train_r)\n",
    "X_test_r_scaled = scaler_r.transform(X_test_r)\n",
    "\n",
    "# Train new model\n",
    "model_r = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_r.fit(X_train_r_scaled, y_train_r)\n",
    "\n",
    "# Evaluate new model\n",
    "y_pred_r = model_r.predict(X_test_r_scaled)\n",
    "print(classification_report(y_test_r, y_pred_r))\n",
    "\n",
    "# Save the reduced-feature model, scaler, and feature names for deployment\n",
    "import joblib\n",
    "joblib.dump(model_r, 'student_grade_model.pkl')\n",
    "joblib.dump(scaler_r, 'scaler.pkl')\n",
    "joblib.dump(top_features, 'feature_names.pkl')\n",
    "print('Reduced-feature model, scaler, and feature names saved for deployment (15 features).')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
